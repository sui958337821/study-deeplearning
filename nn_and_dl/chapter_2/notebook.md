## 权重和偏置
这里把 − θ 命名为偏置 b，但是请注意，偏置和权重 w1、w2 的作用是不 一样的。具体地说，w1 和 w2 是控制输入信号的重要性的参数，而偏置是调整神经元被激活的容易程度(输出信号为 1 的程度)的参数。比如，若 b 为 −0.1，则只要输入信号的加权总和超过 0.1，神经元就会被激活。但是如果 b 为 −20.0，则输入信号的加权总和必须超过 20.0，神经元才会被激活。像这样， 偏置的值决定了神经元被激活的容易程度。另外，这里我们将 w1 和 w2 称为权重， 将 b 称为偏置，但是根据上下文，有时也会将 b、w1、w2 这些参数统称为权重。
## 感知机的局限性
感知机的局限性就在于它只能表示由一条直线分割的空间。
## 阶跃函数与sigmoid函数的共同性质
阶跃函数和 sigmoid 函数的共同性质。阶跃函数和 sigmoid 函数虽然在平滑性上有差异，但是如果从宏观视角看图 3-8，可以发现它们 具有相似的形状。实际上，两者的结构均是“输入小时，输出接近 0(为 0); 随 着 输 入 增 大 ， 输 出 向 1 靠 近 ( 变 成 1 )”。 也 就 是 说 ， 当 输 入 信 号 为 重 要 信 息 时 ， 阶跃函数和 sigmoid 函数都会输出较大的值;当输入信号为不重要的信息时， 两者都输出较小的值。还有一个共同点是，不管输入信号有多小，或者有多 大，输出信号的值都在 0 到 1 之间。
## 非线性函数
神经网络的激活函数必须使用非线性函数。换句话说，激活函数不能使用线性函数。为什么不能使用线性函数呢?因为使用线性函数的话，加深神经网络的层数就没有意义了。